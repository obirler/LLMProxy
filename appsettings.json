{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning",
      "LLMProxy": "Information" // Set specific level for your app's logs
    }
  },
  "AllowedHosts": "*",
  "RoutingConfig": { // Match the structure in RoutingConfig.cs
    "Models": {
      "gpt-4-turbo": { // Example Model Name
        "Strategy": "Failover", // Or "RoundRobin", "Weighted"
        "Backends": [
          {
            "Name": "OpenAI-Primary",
            "BaseUrl": "https://api.openai.com/v1", // Include /v1
            "ApiKeys": [ "YOUR_OPENAI_KEY_1" ], // Replace with actual keys
            "Weight": 1,
            "Enabled": true
          },
          {
            "Name": "OpenAI-Backup",
            "BaseUrl": "https://api.openai.com/v1",
            "ApiKeys": [ "YOUR_OPENAI_KEY_2" ],
            "Weight": 1,
            "Enabled": true
          }
        ]
      },
      "deepseek-chat": {
        "Strategy": "RoundRobin",
        "Backends": [
          {
            "Name": "DeepSeek-EU",
            "BaseUrl": "https://api.deepseek.com/v1", // Include /v1
            "ApiKeys": [ "YOUR_DEEPSEEK_KEY_1" ],
            "Weight": 1,
            "Enabled": true
          },
          {
            "Name": "DeepSeek-US", // Assuming different endpoints or just keys
            "BaseUrl": "https://api.deepseek.com/v1",
            "ApiKeys": [ "YOUR_DEEPSEEK_KEY_2" ],
            "Weight": 1,
            "Enabled": true
          }
        ]
      },
      "mistral-large-latest": {
        "Strategy": "Failover",
        "Backends": [
          {
            "Name": "MistralAI",
            "BaseUrl": "https://api.mistral.ai/v1", // Include /v1
            "ApiKeys": [ "YOUR_MISTRAL_KEY" ],
            "Weight": 1,
            "Enabled": true
          },
          { // Example: Failover to a different provider model if Mistral fails
            "Name": "OpenAI-GPT4-Turbo-Failover",
            "BaseUrl": "https://api.openai.com/v1",
            "ApiKeys": [ "YOUR_OPENAI_KEY_3" ],
            "Weight": 1,
            "Enabled": true
            // Note: Client must send 'mistral-large-latest' but proxy routes to gpt-4 if mistral fails.
            // The receiving backend (OpenAI here) needs to support the *original model request format*
            // or you need transformation logic (which adds complexity). Usually, failover is between
            // instances of the *same* model type or compatible ones.
          }
        ]
      },
      // Add configurations for other models like /v1/embeddings etc.
      // Use a distinct model name even if it hits the same endpoint type,
      // e.g., "text-embedding-ada-002"
      "text-embedding-ada-002": {
        "Strategy": "Failover",
        "Backends": [
          {
            "Name": "OpenAI-Embed",
            "BaseUrl": "https://api.openai.com/v1",
            "ApiKeys": [ "YOUR_OPENAI_KEY_EMBED" ],
            "Enabled": true
          }
        ]
      }
    }
  },
  "Kestrel": { // Optional: Configure Kestrel if needed
    "Endpoints": {
      "Http": {
        "Url": "http://*:7548" // Example: Listen on port 7548
      }
    }
  }
}